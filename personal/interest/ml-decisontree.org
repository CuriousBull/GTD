
* 什么是决策树 (Decision Tree)

  #+BEGIN_QUOTE
  决策树类似于一个流程图的树结构，其中：每个内部节点表示在一个属性上的测试，每个分支表示一个属性输出，
  而每个树叶节点代表类或类分布。树的最顶层是根节点。
  #+END_QUOTE

  [[file:decisiontree/decisiontree_01.jpg][决策树示意图]] 

* 如何创建决策树

** 熵的定义 (Entropy)

   [[https://www.zhihu.com/question/22178202][信息熵的讨论]]

   定义如下：

   #+BEGIN_SRC latex
     \begin{equation}
       H(x) = \sum_{x}p(x)\log_2 p(x)
     \end{equation}
   #+END_SRC

** 决策树归纳算法 -- ID3

   1. 选择属性判断节点 -- 信息获取量

      #+BEGIN_SRC latex
        \begin{equation}
          Gain(A) = Info(D) - Info_A(D)
        \end{equation}
      #+END_SRC

      通过 A 来作为节点分类，获取多少信息

   2. 算法具体流程

      - 树以代表训练样本的单个节点开始

      - 如果样本都在同一个类，则该节点称为树叶，并用该类标号

      - 否则，算法使用称为信息增益的基于熵的度量作为启发信息，选择能够最好地将样本
        分类的属性。该属性成为该节点的“测试”或“判定”属性。

      - 在该版本算法中

        - 所有属性都是分类的，即离散值，连续属性必须离散化

        - 对测试属性的每个已知值，创建一个分支，并以此划分样本

        - 算法使用同样过程，递归形成每个划分上的样本判定树，一旦一个属性出现在一个
          节点上，就不必在该节点任何后代上考虑它。

      - 递归步骤仅当下列条件之一成立

        - 给定节点所有样本属于同一类

        - 没有剩余属性可用于划分样本，此时使用多数表决

      - 分枝

** 决策树归纳算法 -- CS4.5
      

